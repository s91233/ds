{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install geoplot geopandas geodatasets researchpy feature-engine streamlit"
      ],
      "metadata": {
        "id": "WCCQVOUcCL6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L https://github.com/s91233/ds/blob/main/archive.zip?raw=true | jar xv"
      ],
      "metadata": {
        "id": "kpNm4n821sYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import probplot\n",
        "from textblob import TextBlob\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "df = pd.read_csv('Airbnb_Open_Data.csv')\n",
        "df.describe\n",
        "df.info()\n",
        "df.head()\n",
        "df"
      ],
      "metadata": {
        "id": "p85TA6mD1-YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.select_dtypes(include=np.number).columns:\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # QQ-plot\n",
        "    probplot(df[col], plot=ax[0], fit=True)\n",
        "    ax[0].set_title(f'QQ-Plot for {col}')\n",
        "\n",
        "    # Histogram & PDF\n",
        "    sns.histplot(df[col], kde=True, ax=ax[1])\n",
        "    ax[1].set_title(f'Pdf & Histogram for {col}')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "a7Wlp-emCto9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean & Convert\n",
        "\n",
        "df = df.drop(columns=['id','NAME','host id','host name','country','country code','license'], axis=1)\n",
        "df.rename(columns=lambda x: x.strip().lower().replace(' ', '_'), inplace=True)\n",
        "\n",
        "df['last_review'] = pd.to_datetime(df['last_review'], format='%m/%d/%Y')\n",
        "\n",
        "df['price'] = df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
        "df['service_fee'] = df['service_fee'].replace('[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "for column in df.columns:\n",
        "    if column in ['price', 'service_fee', 'lat', 'long']:\n",
        "        df[column].fillna(df[column].mean(), inplace=True)\n",
        "    elif df[column].dtype == 'numeric':\n",
        "        df[column].fillna(df[column].mean().round(0), inplace=True)\n",
        "    else:\n",
        "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "        df[column] = pd.Categorical(df[column])\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "1qZjvvWRFg1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the NYC Boro GeoDataFrame and ensure it's in EPSG:4326 (GPS)\n",
        "nyc_boroughs = gpd.GeoDataFrame.from_file(gpd.datasets.get_path(\"nybb\")).to_crs(epsg=4326)\n",
        "\n",
        "# Create GeoDataFrame and set CRS to EPSG:4326\n",
        "points = gpd.points_from_xy(df[\"long\"], df[\"lat\"])\n",
        "gdf = gpd.GeoDataFrame(df, geometry=points, crs=\"EPSG:4326\")\n",
        "\n",
        "# Ensure geometries are valid\n",
        "gdf[\"geometry\"] = gdf[\"geometry\"].make_valid()\n",
        "nyc_boroughs[\"geometry\"] = nyc_boroughs[\"geometry\"].make_valid()\n",
        "\n",
        "# Perform spatial join with 'within' predicate\n",
        "gdf_joined = gpd.sjoin(gdf, nyc_boroughs, how=\"left\", predicate=\"within\")\n",
        "\n",
        "# Replace mismatching neighbourhood_groups\n",
        "gdf[\"correct_borough\"] = gdf_joined[\"BoroName\"]\n",
        "incorrect_locations = df[gdf[\"neighbourhood_group\"] != gdf[\"correct_borough\"]]\n",
        "display(incorrect_locations)\n",
        "df[\"neighbourhood_group\"] = gdf[\"correct_borough\"]\n"
      ],
      "metadata": {
        "id": "yON34_krI1Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Ensure that \"house_rules\" column has string data type\n",
        "df[\"house_rules\"] = df[\"house_rules\"].astype(str)\n",
        "\n",
        "# Calculate sentiment polarity for each text\n",
        "df[\"house_rules_sentiment\"] = df[\"house_rules\"].apply(\n",
        "    lambda text: TextBlob(text).sentiment.polarity\n",
        ")\n",
        "\n",
        "# Categorize house rules based on sentiment scores\n",
        "df[\"house_rules\"] = df[\"house_rules_sentiment\"].apply(\n",
        "    lambda score: (\n",
        "        \"strict\" if score < -0.2 else (\"neutral\" if -0.2 <= score <= 0.2 else \"relaxed\")\n",
        "    )\n",
        ")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "dKNB2lPp9-xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('Airbnb_Open_Data_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "MZZnnxgy8MrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load your preprocessed data\n",
        "df = pd.read_csv('Airbnb_Open_Data_cleaned.csv')\n",
        "\n",
        "# Prepare your features and target variable\n",
        "X = df[['price']]\n",
        "y = df['service_fee']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Streamlit app\n",
        "st.title(\"Service Fee Recommender\")\n",
        "\n",
        "# Input for price\n",
        "price = st.number_input(\"Enter the price of the listing:\", min_value=0.0)\n",
        "\n",
        "# Make prediction when button is clicked\n",
        "if st.button(\"Recommend Service Fee\"):\n",
        "    predicted_fee = model.predict([[price]])[0]\n",
        "    st.success(f\"Recommended service fee: ${predicted_fee:.2f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "noFPXIwGvw5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel -g"
      ],
      "metadata": {
        "id": "bKRHQAG02Ofz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl icanhazip.com"
      ],
      "metadata": {
        "id": "1VyvHUQBBWRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.address=localhost & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "sjfS5laxwx2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YEutHTZaAQcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlations\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap'); plt.show()\n",
        "#sns.pairplot(df.select_dtypes(include=np.number)); plt.show()"
      ],
      "metadata": {
        "id": "0Mfb84sxJeut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import geopandas as gpd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.offline import iplot, plot, download_plotlyjs, init_notebook_mode\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "nyc_boroughs = gpd.GeoDataFrame.from_file(gpd.datasets.get_path('nybb')).to_crs(epsg=4326)\n",
        "\n",
        "fig = px.scatter_mapbox(\n",
        "    df,\n",
        "    lat= \"lat\",\n",
        "    lon= \"long\",\n",
        "    color=\"room_type\",\n",
        "    center={\"lat\": 40.7128, \"lon\": -74.0060},\n",
        "    zoom=10,\n",
        "    mapbox_style=\"carto-positron\",\n",
        ")\n",
        "go.Figure(fig).add_choroplethmapbox(\n",
        "    geojson=nyc_boroughs.geometry.__geo_interface__,\n",
        "    locations=nyc_boroughs.index,\n",
        "    z=nyc_boroughs.index,\n",
        "    colorscale=\"Viridis\",\n",
        "    marker_opacity=0.5,\n",
        "    marker_line_width=1,\n",
        "    below=\"traces\"\n",
        ").show()\n",
        "\n",
        "fig = px.scatter_mapbox(df, lat='lat', lon='long', zoom=10,\n",
        "    color='neighbourhood_group',\n",
        "    mapbox_style=\"carto-positron\",\n",
        "    center={\"lat\": 40.7128, \"lon\": -74.0060},\n",
        ")\n",
        "go.Figure(fig).add_choroplethmapbox(\n",
        "    geojson=nyc_boroughs.geometry.__geo_interface__,\n",
        "    locations=nyc_boroughs.index,\n",
        "    z=nyc_boroughs.index,\n",
        "    colorscale=\"Viridis\",\n",
        "    marker_opacity=0.5,\n",
        "    marker_line_width=1,\n",
        "    below=\"traces\"\n",
        ").show()\n",
        "\n",
        "fig = px.scatter_mapbox(\n",
        "        df,\n",
        "        lat=\"lat\",\n",
        "        lon=\"long\",\n",
        "        color=\"house_rules\",\n",
        "        mapbox_style=\"carto-positron\",\n",
        "        center={\"lat\": 40.7128, \"lon\": -74.0060},\n",
        "        zoom=9\n",
        ")\n",
        "go.Figure(fig).add_choroplethmapbox(\n",
        "    geojson=nyc_boroughs.geometry.__geo_interface__,\n",
        "    locations=nyc_boroughs.index,\n",
        "    z=nyc_boroughs.index,\n",
        "    colorscale=\"Viridis\",\n",
        "    marker_opacity=0.5,\n",
        "    marker_line_width=1,\n",
        "    below=\"traces\"\n",
        ").show()\n",
        "\n",
        "fig = px.density_mapbox(\n",
        "    df,\n",
        "    lat=\"lat\",\n",
        "    lon=\"long\",\n",
        "    z=\"review_rate_number\",\n",
        "    radius=10,\n",
        "    center={\"lat\": 40.7128, \"lon\": -74.0060},\n",
        "    zoom=9,\n",
        "    mapbox_style=\"carto-positron\"\n",
        ")\n",
        "go.Figure(fig).add_choroplethmapbox(\n",
        "    geojson=nyc_boroughs.geometry.__geo_interface__,\n",
        "    locations=nyc_boroughs.index,\n",
        "    z=nyc_boroughs.index,\n",
        "    colorscale=\"Viridis\",\n",
        "    marker_opacity=0.5,\n",
        "    marker_line_width=1,\n",
        "    below=\"traces\"\n",
        ").show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2IwmZVZzNkQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "plt.subplots(figsize=(25,15))\n",
        "wordcloud = WordCloud(\n",
        "                          background_color='white',\n",
        "                          width=1920,\n",
        "                          height=1080\n",
        "                         ).generate(\" \".join(df.neighbourhood))\n",
        "plt.imshow(wordcloud)\n",
        "plt.savefig('neighbourhood.png')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5H8q8Uy05JkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(0/0)"
      ],
      "metadata": {
        "id": "zXRmD_qCW3sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hlcIgn63SW77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stratification_columns = ['neighbourhood_group', 'room_type', 'house_rules']\n",
        "\n",
        "TARGET = \"service_fee\"\n",
        "EPOCHS = 100\n",
        "SPLITS = 10\n",
        "\n",
        "import tensorflow as tf\n",
        "from tqdm.auto import tqdm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Combine the specified columns into a single stratification column\n",
        "df['stratification'] = df[stratification_columns].apply(lambda x: ''.join(x.astype(str)), axis=1)\n",
        "\n",
        "X = df.drop([TARGET, 'stratification', 'last_review'], axis=1)\n",
        "\n",
        "# Convert categorical columns to numerical labels\n",
        "label_encoders = {}\n",
        "for col in X.select_dtypes(include=['object','category']).columns:\n",
        "  le = LabelEncoder()\n",
        "  X[col] = le.fit_transform(X[col])\n",
        "  label_encoders[col] = le\n",
        "\n",
        "y = df[TARGET]  # Target variable\n",
        "\n",
        "models = [\n",
        "    LinearRegression(),\n",
        "    MLPRegressor(random_state=42),\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    GradientBoostingRegressor(random_state=42)\n",
        "]\n",
        "\n",
        "skf = StratifiedKFold(n_splits=SPLITS, shuffle=True, random_state=42)\n",
        "for model in models:\n",
        "  print(f\"Training {type(model).__name__}\")\n",
        "  for i, (train_index, test_index) in enumerate(skf.split(X, df['stratification']), start=1):\n",
        "    print(f\"Training fold {i} out of {skf.get_n_splits()}\")\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"RMSE: {mean_squared_error(y_test, model.predict(X_test), squared=False)}\")\n",
        "\n",
        "# NN\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Normalize the numerical features\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_train))\n",
        "\n",
        "model = keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam())\n",
        "\n",
        "print(f\"Training {type(model).__name__}\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=0.2,\n",
        "    verbose=1)\n",
        "models.append(model)\n",
        "print(f\"RMSE: {model.evaluate(X_test, y_test, verbose=0)}\")\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "df = df.drop('stratification', axis=1)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "colors = plt.cm.rainbow(np.linspace(0, 1, len(models)))\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Handle the 2D output of the neural network\n",
        "    if isinstance(y_pred, np.ndarray) and y_pred.ndim == 2:\n",
        "        y_pred = y_pred.flatten()  # Flatten to 1D\n",
        "    # Predictions\n",
        "    axes[0].scatter(y_test, y_pred, alpha=0.5, label=type(model).__name__, color=colors[i])\n",
        "    # Residuals\n",
        "    axes[1].scatter(y_pred, y_test - y_pred, alpha=0.5, label=type(model).__name__, color=colors[i])\n",
        "\n",
        "axes[0].legend()\n",
        "axes[0].set_xlabel(\"Actual\")\n",
        "axes[0].set_ylabel(\"Predicted\")\n",
        "axes[0].set_title(\"Actual vs Predicted\")\n",
        "\n",
        "axes[1].legend()\n",
        "axes[1].set_xlabel(\"Predicted\")\n",
        "axes[1].set_ylabel(\"Residuals\")\n",
        "axes[1].set_title(\"Residuals vs Predicted\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AuORHE_IvEPm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}